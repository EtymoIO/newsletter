<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
	<title>Etymo AI newsletter #7</title>
	<style type="text/css">
		#outlook a {padding:0;}
		body{width:100% !important; -webkit-text-size-adjust:100%; -ms-text-size-adjust:100%; margin:0; padding:0; font-family: "Open Sans", sans-serif;}
		.ExternalClass {width:100%;}
		.ExternalClass, .ExternalClass p, .ExternalClass span, .ExternalClass font, .ExternalClass td, .ExternalClass div {line-height: 100%;}
		#backgroundTable {margin:0; padding:0; width:100% !important; line-height: 100% !important;}
		img {outline:none; text-decoration:none; -ms-interpolation-mode: bicubic;}
		a img {border:none;}
		.image_fix {display:block;}
		p {margin: 1em 0;}
		h1, h2, h4, h5, h6 {color: black !important; font-weight:300; text-align:center;}
		h3 {font-weight:300; text-align:center;}
		h1 a, h2 a, h3 a, h4 a, h5 a, h6 a {color: blue !important;}
		h1 a:active, h2 a:active,  h3 a:active, h4 a:active, h5 a:active, h6 a:active {
			color: red !important;
		}
		h2 {font-size:4rem;}
		h3 {font-size:1.75rem; color:blue;}
		h4 {font-size:1.3rem;}

		h1 a:visited, h2 a:visited,  h3 a:visited, h4 a:visited, h5 a:visited, h6 a:visited {
			color: purple !important;
		}
		table td {border-collapse: collapse;}
		table { border-collapse:collapse; mso-table-lspace:0pt; mso-table-rspace:0pt; }
		a {color: blue;}
		@media only screen and (max-device-width: 480px) {
			a[href^="tel"], a[href^="sms"] {
						text-decoration: none;
						color: black; /* or whatever your want */
						pointer-events: none;
						cursor: default;
					}

			.mobile_link a[href^="tel"], .mobile_link a[href^="sms"] {
						text-decoration: default;
						color: blue !important; /* or whatever your want */
						pointer-events: auto;
						cursor: default;
					}
		}

		@media only screen and (min-device-width: 768px) and (max-device-width: 1024px) {
			a[href^="tel"], a[href^="sms"] {
						text-decoration: none;
						color: blue;
						pointer-events: none;
						cursor: default;
					}

			.mobile_link a[href^="tel"], .mobile_link a[href^="sms"] {
						text-decoration: default;
						color: blue !important;
						pointer-events: auto;
						cursor: default;
					}
		}

		.section{
			padding:10px;
		}
		#backgroundTable{
			width:100%;
			max-width:800px;
			margin:0 auto;
		}
		th{
			text-align:left;
		}
		.padded td, th{
			padding:5px 10px;
		}

		li{
			margin:10px;
		}

		@media only screen and (-webkit-min-device-pixel-ratio: 2) {
			/* Put your iPhone 4g styles in here */
		}
		@media only screen and (-webkit-device-pixel-ratio:.75){
			/* Put CSS for low density (ldpi) Android layouts in here */
		}
		@media only screen and (-webkit-device-pixel-ratio:1){
			/* Put CSS for medium density (mdpi) Android layouts in here */
		}
		@media only screen and (-webkit-device-pixel-ratio:1.5){
			/* Put CSS for high density (hdpi) Android layouts in here */
		}
	</style>



</head>
<body>
	<table cellpadding="0" cellspacing="0" border="0" id="backgroundTable" style="background-color:#ffffff;">
	<tr>
		<td class="section" style="text-align:center;padding:10px;">
			<h1>
				<img class="image_fix" src="https://s3.eu-west-2.amazonaws.com/newsletter.etymo.io/template/header.png" alt="newsletter.etymo" title="newsletter.etymo" style="width:100%	;max-width:600px; margin:0px auto;" />
			</h1>
		</td>
	</tr>
	<tr>
		<td class="section" style="text-align:center;">
			<h2 style="font-weight:300; font-size:2rem;">16th November - 29th November 2018</h2>
			<h3 style="color:blue;">
				2000 new papers
			</h3>
		</td>
	</tr>
	<tr>
		<td class="section">
			<p>
				In this newsletter from Etymo, you can find out the latest development in machine learning research, including the most popular datasets used, the most frequently appearing keywords, the important research papers associated with the keywords, and the most trending papers in the past two weeks.<br /><br />
If you and your friends like this newsletter, you can subscribe to our fortnightly newsletters <a href="https://docs.google.com/forms/d/e/1FAIpQLScPzDcOp6gnVWtiXtLOG_uFff0Fg7uEuXqg0cu5LiCNkq637Q/viewform">here</a>.
			</p>
		</td>
	</tr>
	<tr>
		<td class="section">
			<h3>
				Fortnight Summary
			</h3>
		<p>
			Again computer vision (CV) is still strong, as reflected on the popularity of the CV datasets and the most trending papers. Very little change with the most popular datasets, mainly just a reshuffle of the ordering.<br></br>

			Generative Adversarial Networks (GANs) have been popular over the last two weeks with (<a href="https://arxiv.org/pdf/1811.10597v1.pdf">GAN Dissection: Visualizing and Understanding Generative Adversarial Networks</a>) developing a new framework to help visualise and understand GANs on a unit level, and (<a href="https://arxiv.org/pdf/1811.12402v1.pdf">On the Implicit Assumptions of GANs</a>) which explain the problems with GANs that apparently contradict theoretical guarantees and provide an alternative approach which sidestep these problems. For anyone unfamiliar with GANs, we recommend <a href="https://arxiv.org/pdf/1701.00160v4.pdf">NIPS 2016 Tutorial: Generative Adversarial Networks</a> by Ian Goodfellow. <br></br>

			We present the emerging interests in research under the "Trending Phrases" section. The papers in this section shows some cutting edge results, <a href="http://arxiv.org/abs/1810.07096v2">Incremental learning abstract discrete planning domains and mappings to continuous perceptions</a> provides a new framework for planning (model based) reinforcement learning. They allow the agent to dynamically learn new states, map between states and real world, and update these mapping along the life of the agent. <a href="http://arxiv.org/abs/1712.01949v2">Recognizing Plans by Learning Embeddings from Observed Action Distributions</a> also explores planning domain, where they apply Word2Vec on actions to construct plans. They develop a UDUP (Uncertain DUP|) algorithm, where DUP was originally developed in  <a href="https://arxiv.org/pdf/1511.05662.pdf">Discovering Underlying Plans Based on Distributed Representations of Actions</a>.
			<a href="http://arxiv.org/abs/1811.11168v2">Deformable ConvNets v2: More Deformable, Better Results </a> explores spatial support where they present a reformulation of Deformable ConvNets that improves its ability to focus on pertinent image regions. Finally <a href="http://arxiv.org/abs/1811.08115v2">Sequence-based Person Attribute Recognition with Joint CTC-Attention Model</a> propose a joint CTC-Attention model, which maps attribute labels into sequences to learn the semantic relationship among attributes. Attribute recognition is widely used in many computer vision tasks.<br></br>

			The trending of the last two weeks are from Google and Deepmind, a shot summary of each trending paper is given in the section below.<br></br>

			Other noticable mentions include <a href="https://arxiv.org/pdf/1811.10495v1.pdf">ExpandNets: Exploiting Linear Redundancy to Train Small Networks</a>, which introduces another alternative approach to training a small network. They propose to expand each linear layer of a small network into multiple linear layers, without adding any nonlinearity. <a href="https://arxiv.org/pdf/1811.10154v1.pdf">Please Stop Explaining Black Box Models for High Stakes Decisions</a> want authors to stop explaining black box models, and start creating models that are interpretable in the first place. And finally <a href="https://arxiv.org/pdf/1811.10959v1.pdf">Dataset Distillation</a> which tries to distill a large dataset into a smaller one. This idea is to form a smaller dataset using the the larger dataset and then train on the smaller dataset instead. They compare their method on the ImageNet and CIFAR-10 datasets.
		</p>

		</td>
	</tr>
	<tr>
		<td class="section">
			<h3>
				Popular Datasets
			</h3>
			<p>
				Computer vision is still the main focus area of research. Remember, Yelp are still holding the 12th Yelp Dataset Challenge till Dec 31, 2018, including categories of photo classification, natural language processing and graph mining.
			</p>
			<table class="padded">
			<tr>
			        <th>Name</th>
			        <th>Type</th>
			        <th>Number of Papers</th>
			</tr>
			<tr>
				<td><a href="http://yann.lecun.com/exdb/mnist/">MNIST</a></td>
				<td>Handwritten Digits</td>
			        <td>83</td>
			</tr>
			<tr>
				<td><a href="http://www.image-net.org">ImageNet</a></td>
				<td>Image Dataset</td>
						<td>63</td>
			</tr>
			<tr>
				<td><a href="http://cocodataset.org/#home">COCO</a></td>
				<td>Common Objects in Context</td>
						<td>36</td>
			</tr>
			<tr>
				<td><a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a></td>
				<td>Tiny Image Dataset in 10 Classes</td>
						<td>34</td>
			</tr>
			<tr>
				<td><a href="http://www.cvlibs.net/datasets/kitti/">KITTI</a></td>
				<td>Autonomous Driving</td>
						<td>21</td>
			</tr>
			<tr>
				<td><a href="http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html">CelebA</a></td>
				<td>Large-scale CelebFaces Attributes</td>
						<td>21</td>
			</tr>
			<tr>
				<td><a href="https://rgbd-dataset.cs.washington.edu">RGB-D</a></td>
				<td>Scenes Dataset</td>
					<td>17</td>
			</tr>
			</table>
		</td>
	</tr>

	<tr>
		<td class="section">
			<h3>
				Trending Phrases
			</h3>
			<p>
				In this section, we present a list of words/ phrases that appeared significantly more in this newsletter than the previous newsletters.
			</p>
			<ul> <b>Planning domain</b>:
				<li>
					<a href="http://arxiv.org/abs/1810.07096v2">Incremental learning abstract discrete planning domains and mappings to continuous perceptions</a>
				</li>
				<li>
					<a href="http://arxiv.org/abs/1712.01949v2">Recognizing Plans by Learning Embeddings from Observed Action Distributions</a>
				</li>
				<br /> <b>Spatial support</b>:
				<li>
					<a href="http://arxiv.org/abs/1811.11168v2">Deformable ConvNets v2: More Deformable, Better Results</a>
				</li>
				<br /> <b>Attribute recognition</b>:
				<li>
					<a href="http://arxiv.org/abs/1811.08115v2">Sequence-based Person Attribute Recognition with Joint CTC-Attention Model</a>
				</li>
			</ul>
		</td>
	</tr>


	<tr>
		<td>
			<h3>
				Etymo Trending
			</h3>
			<p>
				Presented below is a list of the most trending papers added in the last two weeks.
			</p>
			<ul>
				<li>
					<a href="https://arxiv.org/abs/1811.07871v1">Scalable agent alignment via reward modeling: a research direction</a>:
					<br />
					The 30 page paper from Deepmind highlights a research direction to solve the agent alignment problem centered around reward modeling. The idea behind reward modelling is to construct a reward function based on user interaction, which can then be used during reinforcement learning. The paper provides a brief literature review and then explains many open problems in the subject.
				</li>
				<br />
				<li>
					<a href="https://arxiv.org/abs/1811.10104v1">50 Years of Test (Un)fairness: Lessons for Machine Learning</a>:
					<br />
					This short paper from Google discusses the definition of `unfairness' in machine learning over the last 50 years. Each decade is given a short section and a detailed overview is provided at the end.
				</li>
				<br />
				<li>
					<a href="https://arxiv.org/abs/1807.04587v2">Assessing the Scalability of Biologically-Motivated Deep Learning Algorithms and Architectures</a>:
					<br />
					Again Deepmind and Google Brain explore variants of target-propagation (TP) and feedback alignment (FA) algorithms for deep neural nets. Results are presented on results on the MNIST, CIFAR-10, and ImageNet datasets. Then conclude that both approached perform significantly worse than backpropogation.
				</li>
			</ul>
		</td>
	</tr>

	<tr>
		<td class="section">
			<h3>
				Frequent Words
			</h3>

			<p>
				"Learning", "Model", "Data" and "Training" are the most frequent words. The top two papers associated with each of the key words are:
			</p>
			<ul> <b>Model</b>:
				<li>
					<a href="http://arxiv.org/abs/1811.09231v1">Verification of Planning Domain Models - Revisited</a>
				</li>
				<li>
					<a href="http://arxiv.org/abs/1811.09712v1">Dancing in the Dark: Private Multi-Party Machine Learning in an Untrusted Setting</a>
				</li>
				<br /> <b>Learning</b>:
				<li>
					<a href="http://arxiv.org/abs/1701.07274v6">Deep Reinforcement Learning: An Overview</a>
				</li>
				<li>
					<a href="http://arxiv.org/abs/1811.10052v1">An overview of deep learning in medical imaging focusing on MRI</a>
				</li>
				<br /> <b>Data</b>:
				<li>
					<a href="http://arxiv.org/abs/1811.04364v2">A Survey of Mixed Data Clustering Algorithms"</a>
				</li>
				<li>
					<a href="http://arxiv.org/abs/1802.08254v2">BigDataBench: A Scalable and Unified Big Data and AI Benchmark Suite</a>
				</li>
				<br /> <b>Training</b>:
				<li>
					<a href="http://arxiv.org/abs/1803.03635v4">The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks</a>
				</li>
				<li>
					<a href="http://arxiv.org/abs/1811.09347v1">Revisiting Pre-training: An Efficient Training Method for Image Classification</a>
				</li>
			</ul>
		</td>
	</tr>

	<tr>
	<td class="section">
		<h4 style="line-height:1.25">
				Hope you have enjoyed this newsletter! If you have any comments or suggestions, please email ernest@etymo.io or steven@etymo.io.
		</h4>
	</td>
	</tr>
	</table>

</body>
</html>
