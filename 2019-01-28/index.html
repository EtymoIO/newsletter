<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
	<title>Etymo AI newsletter #12</title>
	<style type="text/css">
		#outlook a {padding:0;}
		body{width:100% !important; -webkit-text-size-adjust:100%; -ms-text-size-adjust:100%; margin:0; padding:0; font-family: "Open Sans", sans-serif;}
		.ExternalClass {width:100%;}
		.ExternalClass, .ExternalClass p, .ExternalClass span, .ExternalClass font, .ExternalClass td, .ExternalClass div {line-height: 100%;}
		#backgroundTable {margin:0; padding:0; width:100% !important; line-height: 100% !important;}
		img {outline:none; text-decoration:none; -ms-interpolation-mode: bicubic;}
		a img {border:none;}
		.image_fix {display:block;}
		p {margin: 1em 0;}
		h1, h2, h4, h5, h6 {color: black !important; font-weight:300; text-align:center;}
		h3 {font-weight:300; text-align:center;}
		h1 a, h2 a, h3 a, h4 a, h5 a, h6 a {color: blue !important;}
		h1 a:active, h2 a:active,  h3 a:active, h4 a:active, h5 a:active, h6 a:active {
			color: red !important;
		}
		h2 {font-size:4rem;}
		h3 {font-size:1.75rem; color:blue;}
		h4 {font-size:1.3rem;}

		h1 a:visited, h2 a:visited,  h3 a:visited, h4 a:visited, h5 a:visited, h6 a:visited {
			color: purple !important;
		}
		table td {border-collapse: collapse;}
		table { border-collapse:collapse; mso-table-lspace:0pt; mso-table-rspace:0pt; }
		a {color: blue;}
		@media only screen and (max-device-width: 480px) {
			a[href^="tel"], a[href^="sms"] {
						text-decoration: none;
						color: black; /* or whatever your want */
						pointer-events: none;
						cursor: default;
					}

			.mobile_link a[href^="tel"], .mobile_link a[href^="sms"] {
						text-decoration: default;
						color: blue !important; /* or whatever your want */
						pointer-events: auto;
						cursor: default;
					}
		}

		@media only screen and (min-device-width: 768px) and (max-device-width: 1024px) {
			a[href^="tel"], a[href^="sms"] {
						text-decoration: none;
						color: blue;
						pointer-events: none;
						cursor: default;
					}

			.mobile_link a[href^="tel"], .mobile_link a[href^="sms"] {
						text-decoration: default;
						color: blue !important;
						pointer-events: auto;
						cursor: default;
					}
		}

		.section{
			padding:10px;
		}
		#backgroundTable{
			width:100%;
			max-width:800px;
			margin:0 auto;
		}
		th{
			text-align:left;
		}
		.padded td, th{
			padding:5px 10px;
		}

		li{
			margin:10px;
		}

		@media only screen and (-webkit-min-device-pixel-ratio: 2) {
			/* Put your iPhone 4g styles in here */
		}
		@media only screen and (-webkit-device-pixel-ratio:.75){
			/* Put CSS for low density (ldpi) Android layouts in here */
		}
		@media only screen and (-webkit-device-pixel-ratio:1){
			/* Put CSS for medium density (mdpi) Android layouts in here */
		}
		@media only screen and (-webkit-device-pixel-ratio:1.5){
			/* Put CSS for high density (hdpi) Android layouts in here */
		}
	</style>



</head>
<body>
	<table cellpadding="0" cellspacing="0" border="0" id="backgroundTable" style="background-color:#ffffff;">
	<tr>
		<td class="section" style="text-align:center;padding:10px;">
			<h1>
				<img class="image_fix" src="https://raw.githubusercontent.com/EtymoIO/newsletter/master/image/header.png" alt="newsletter.etymo" title="newsletter.etymo" style="width:100%	;max-width:600px; margin:0px auto;" />
			</h1>
		</td>
	</tr>
	<tr>
		<td class="section" style="text-align:center;">
			<h2 style="font-weight:300; font-size:2rem;">11th January - 24th January 2019</h2>
			<h3 style="color:blue;">
				1361 new papers
			</h3>
		</td>
	</tr>
	<tr>
		<td class="section">
			<p>
				In this newsletter from Etymo, you can find out the latest development in machine learning research, including the most popular datasets used, the most frequently appearing keywords, the important research papers associated with the keywords, and the most trending papers in the past two weeks.<br/><br/>
If you and your friends like this newsletter, you can subscribe to our fortnightly newsletters <a href="https://docs.google.com/forms/d/e/1FAIpQLScPzDcOp6gnVWtiXtLOG_uFff0Fg7uEuXqg0cu5LiCNkq637Q/viewform">here</a>.
			</p>
		</td>
	</tr>
	<tr>
		<td class="section">
			<h3>
				Fortnight Summary
			</h3>
		<p>
			The number of papers published in the past two weeks is back to 1361, the level we have observed for most part of 2018. Computer vision (CV) is still a main research area, as reflected on the popularity of the CV datasets and the most trending papers.<br></br>

			We present the emerging interests in research under the "Trending Phrases" section. The papers in this section show some cutting edge results. There are two good papers related to <b>Attribute Recognition</b>, an automatically generated description of people's appearance. There is also a new and more consistent algorithm to learn high-quality <b>Node Representation</b> in social and information networks. A very good summary on techniques to tackle <b>False Information</b> is also included. Please read the "Trending Phrases" section for more details.<br></br>

			Other notable development in research includes the following:
			<li>
				A new Neural Architecture Search to include network level structure search for better semantic image segmentation: <a href="https://arxiv.org/abs/1901.02985">Auto-DeepLab: Hierarchical Neural Architecture Search for Semantic Image Segmentation</a>
			</li>
			<li>
				A new Transformer network to learn language dependency beyond a fixed-length context: <a href="https://arxiv.org/abs/1901.02860">Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context</a>
			</li>
			<li>
				An investigation on fundamental requirements for the application of classifier patching on neural networks, an approach for adapting neural network models to handle concept drift in nonstationary environments: <a href="https://arxiv.org/abs/1812.03468">Towards Neural Network Patching: Evaluating Engagement-Layers and Patch-Architectures</a>
			</li>
			<li>
				An answer to a cross-network node classification problem by leveraging the abundant labeled information from a source network to help classify unlabeled nodes in a target network: <a href="https://arxiv.org/abs/1901.07264">Network Embedding for Cross-network Node Classification</a>
			</li>

			<br />
			Some of the notable review papers include:
			<li>
				<a href="https://arxiv.org/abs/1901.03407">Deep Learning for Anomaly Detection: A Survey</a>
			</li>
			<li>
				<a href="https://arxiv.org/abs/1810.13306">Taking Human out of Learning Applications: A Survey on Automated Machine Learning</a>
			</li>
			<li>
				<a href="https://arxiv.org/abs/1901.07858">Evolving the pulmonary nodules diagnosis from classical approaches to deep learning aided decision support: three decades development course and future prospect</a>
			</li>

			<br />
			And some discussion on the direction of machine learning in general include:
			<li>
				A framework to increase the transparency of machine learning technology: <a href="https://arxiv.org/abs/1810.03993">Model Cards for Model Reporting</a>
			</li>
			<li>
				A new principle for exploring context in machine learning models: <a href="https://arxiv.org/abs/1901.03415">Context Aware Machine Learning</a>
			</li>
			<li>
				A framework to extract reproducible knowledge from data that can guide scientific hypothesis generation and experimental design: <a href="https://arxiv.org/abs/1901.08152">Three principles of data science: predictability, computability, and stability (PCS)</a>
			</li>
			<li>
				Discussion about the impact of data science on politics: <a href="https://arxiv.org/abs/1811.03435">Data Science as Political Action: Grounding Data Science in a Politics of Justice</a>
			</li>
		</p>

		</td>
	</tr>
	<tr>
		<td class="section">
			<h3>
				Popular Datasets
			</h3>
			<p>
				Computer vision is still the main focus area of research.
			</p>
			<table class="padded">
			<tr>
			        <th>Name</th>
			        <th>Type</th>
			        <th>Number of Papers</th>
			</tr>
			<tr>
				<td><a href="http://yann.lecun.com/exdb/mnist/">MNIST</a></td>
				<td>Handwritten Digits</td>
			        <td>77</td>
			</tr>
			<tr>
				<td><a href="http://www.image-net.org">ImageNet</a></td>
				<td>Image Dataset</td>
						<td>49</td>
			</tr>
			<tr>
				<td><a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a></td>
				<td>Tiny Image Dataset in 10 Classes</td>
						<td>32</td>
			</tr>
			<tr>
				<td><a href="http://cocodataset.org/#home">COCO</a></td>
				<td>Common Objects in Context</td>
						<td>20</td>
			</tr>
			<tr>
				<td><a href="https://www.cityscapes-dataset.com/">Cityscapes</a></td>
				<td>Images from 50 different cities</td>
					<td>13</td>
			</tr>
			<tr>
				<td><a href="http://www.cvlibs.net/datasets/kitti/">KITTI</a></td>
				<td>Autonomous Driving</td>
						<td>12</td>
			</tr>
			<tr>
				<td><a href="http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html">CelebA</a></td>
				<td>Large-scale CelebFaces Attributes</td>
						<td>11</td>
			</tr>
			</table>
		</td>
	</tr>

	<tr>
		<td class="section">
			<h3>
				Trending Phrases
			</h3>
			<p>
				In this section, we present a list of phrases that appeared significantly more in this newsletter than the previous newsletters.
			</p>
			<ul> <b>Attribute Recognition</b>:
				<li>
					<a href="https://arxiv.org/abs/1901.03756">The Deeper, the Better: Analysis of Person Attributes Recognition</a>
				</li>
				<li>
					<a href="https://arxiv.org/abs/1901.05742">Video-Based Pedestrian Attribute Recognition</a>
				</li>
				<br /> <b>Node Representations</b>:
				<li>
					<a href="https://arxiv.org/abs/1901.04095">Attributed Network Embedding via Subspace Discovery</a>
				</li>
				<br /> <b>False Information</b>:
				<li>
					<a href="https://arxiv.org/abs/1901.06437">Combating Fake News: A Survey on Identification and Mitigation Techniques</a>
				</li>
			</ul>
		</td>
	</tr>


	<tr>
		<td>
			<h3>
				Etymo Trending
			</h3>
			<p>
				Presented below is a list of the most trending papers added in the last two weeks.
			</p>
			<ul>
				<li>
					<a href="https://arxiv.org/abs/1901.03407">Deep Learning for Anomaly Detection: A Survey</a>:
					<br />
					The 50-page paper groups state-of-the-art research techniques into different categories based on the underlying assumptions and approach adopted. Within each category, the authors outline the basic anomaly detection technique, along with its variants and present key assumptions, to differentiate between normal and anomalous behavior, as well as the advantages and limitations of each technique.
				</li>
				<br />
				<li>
					<a href="https://arxiv.org/abs/1901.02985">Auto-DeepLab: Hierarchical Neural Architecture Search for Semantic Image Segmentation</a>:
					<br />
					The author Neural Architecture Search (NAS) for semantic image segmentation, an important computer vision task that assigns a semantic label to every pixel in an image. The authors propose to search the network level structure in addition to the cell level structure, which forms a hierarchical architecture search space. They present a network level search space that includes many popular designs, and develop a formulation that allows efficient gradient-based architecture search (3 P100 GPU days on Cityscapes images). They demonstrate the effectiveness of the proposed method on the challenging Cityscapes, PASCAL VOC 2012, and ADE20K datasets.
				</li>
				<br />
				<li>
					<a href="https://arxiv.org/abs/1901.02860">Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context</a>:
					<br />
					This paper proposes a novel neural architecture, Transformer-XL, that enables Transformer to learn dependency beyond a fixed length without disrupting temporal coherence. It consists of a segment-level recurrence mechanism and a novel positional encoding scheme. This method not only enables capturing longer-term dependency, but also resolves the problem of context fragmentation. The code, pretrained models, and hyperparameters are available in both Tensorflow and PyTorch.
				</li>
			</ul>
		</td>
	</tr>

	<tr>
		<td class="section">
			<h3>
				Frequent Words
			</h3>

			<p>
				"Learning", "Model", "Data" and "Network" are the most frequent words. The top two papers associated with each of the key words are:
			</p>
			<ul> <b>Learning</b>:
				<li>
					<a href="https://arxiv.org/abs/1810.13306">Taking Human out of Learning Applications: A Survey on Automated Machine Learning</a>
				</li>
				<li>
					<a href="https://arxiv.org/abs/1901.07858">Evolving the pulmonary nodules diagnosis from classical approaches to deep learning aided decision support: three decades development course and future prospect</a>
				</li>
				<br /> <b>Model</b>:
				<li>
					<a href="https://arxiv.org/abs/1810.03993">Model Cards for Model Reporting</a>
				</li>
				<li>
					<a href="https://arxiv.org/abs/1901.03415">Context Aware Machine Learning</a>
				</li> 
				<br /> <b>Data</b>:
				<li>
					<a href="https://arxiv.org/abs/1901.08152">Three principles of data science: predictability, computability, and stability (PCS)</a>
				</li>
				<li>
					<a href="https://arxiv.org/abs/1811.03435">Data Science as Political Action: Grounding Data Science in a Politics of Justice</a>
				</li>
				<br /> <b>Network</b>:
				<li>
					<a href="https://arxiv.org/abs/1812.03468">Towards Neural Network Patching: Evaluating Engagement-Layers and Patch-Architectures</a>
				</li>
				<li>
					<a href="https://arxiv.org/abs/1901.07264">Network Embedding for Cross-network Node Classification</a>
				</li>
			</ul>
		</td>
	</tr>

	<tr>
	<td class="section">
		<h4 style="line-height:1.25">
				Hope you have enjoyed this newsletter! If you have any comments or suggestions, please email ernest@etymo.io or steven@etymo.io.	
		</h4>
	</td>
	</tr>
	</table>

</body>
</html>
