<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
	<title>Etymo AI newsletter #1</title>
	<style type="text/css">
		#outlook a {padding:0;}
		body{width:100% !important; -webkit-text-size-adjust:100%; -ms-text-size-adjust:100%; margin:0; padding:0; font-family: "Open Sans", sans-serif;}
		.ExternalClass {width:100%;}
		.ExternalClass, .ExternalClass p, .ExternalClass span, .ExternalClass font, .ExternalClass td, .ExternalClass div {line-height: 100%;}
		#backgroundTable {margin:0; padding:0; width:100% !important; line-height: 100% !important;}
		img {outline:none; text-decoration:none; -ms-interpolation-mode: bicubic;}
		a img {border:none;}
		.image_fix {display:block;}
		p {margin: 1em 0;}
		h1, h2, h4, h5, h6 {color: black !important; font-weight:300; text-align:center;}
		h3 {font-weight:300; text-align:center;}
		h1 a, h2 a, h3 a, h4 a, h5 a, h6 a {color: blue !important;}
		h1 a:active, h2 a:active,  h3 a:active, h4 a:active, h5 a:active, h6 a:active {
			color: red !important;
		}
		h2 {font-size:4rem;}
		h3 {font-size:1.75rem; color:blue;}

		h1 a:visited, h2 a:visited,  h3 a:visited, h4 a:visited, h5 a:visited, h6 a:visited {
			color: purple !important;
		}
		table td {border-collapse: collapse;}
		table { border-collapse:collapse; mso-table-lspace:0pt; mso-table-rspace:0pt; }
		a {color: blue;}
		@media only screen and (max-device-width: 480px) {
			a[href^="tel"], a[href^="sms"] {
						text-decoration: none;
						color: black; /* or whatever your want */
						pointer-events: none;
						cursor: default;
					}

			.mobile_link a[href^="tel"], .mobile_link a[href^="sms"] {
						text-decoration: default;
						color: blue !important; /* or whatever your want */
						pointer-events: auto;
						cursor: default;
					}
		}

		@media only screen and (min-device-width: 768px) and (max-device-width: 1024px) {
			a[href^="tel"], a[href^="sms"] {
						text-decoration: none;
						color: blue;
						pointer-events: none;
						cursor: default;
					}

			.mobile_link a[href^="tel"], .mobile_link a[href^="sms"] {
						text-decoration: default;
						color: blue !important;
						pointer-events: auto;
						cursor: default;
					}
		}

		.section{
			padding:10px;
		}
		#backgroundTable{
			width:100%;
			max-width:800px;
			margin:0 auto;
		}
		th{
			text-align:left;
		}
		.padded td, th{
			padding:5px 10px;
		}

		li{
			margin:10px;
		}

		@media only screen and (-webkit-min-device-pixel-ratio: 2) {
			/* Put your iPhone 4g styles in here */
		}
		@media only screen and (-webkit-device-pixel-ratio:.75){
			/* Put CSS for low density (ldpi) Android layouts in here */
		}
		@media only screen and (-webkit-device-pixel-ratio:1){
			/* Put CSS for medium density (mdpi) Android layouts in here */
		}
		@media only screen and (-webkit-device-pixel-ratio:1.5){
			/* Put CSS for high density (hdpi) Android layouts in here */
		}
	</style>



</head>
<body>
	<table cellpadding="0" cellspacing="0" border="0" id="backgroundTable" style="background-color:#ffffff;">
	<tr>
		<td class="section" style="text-align:center;padding:10px;">
			<a href="https://etymoio.github.io/newsletter">
				<h1>
					<img class="image_fix" src="https://etymoio.github.io/newsletter/image/header.png" alt="newsletter.etymo" title="newsletter.etymo" style="color:blue; width:100%; max-width:600px; margin:0px auto;" />
				</h1>
			</a>
		</td>
	</tr>
	<tr>
		<td class="section" style="text-align:center;">
			<h2 style="font-weight:300; font-size:2rem;">10th August - 23rd August 2018</h2>
		</td>
	</tr>
	<tr>
		<td class="section">
			<h3 style="color:blue;">
				1078 new papers
			</h3>
			<p>
				Etymo added 1078 new papers published in the past two weeks. These newly published papers on average have 3.9 authors for each paper. <br /><br />The table below indicates the number of papers added by Etymo each day:
			</p>
			<table class="padded">
				<tr>
					<th>10/08/2018</th>
					<th>11/08/2018</th>
					<th>12/08/2018</th>
					<th>13/08/2018</th>
					<th>14/08/2018</th>
					<th>15/08/2018</th>
					<th>16/08/2018</th>
				</tr>
				<tr>
					<td>79</td>
					<td>51</td>
					<td>43</td>
					<td>100</td>
					<td>133</td>
					<td>91</td>
					<td>106</td>
				</tr>
			</table>
			<table class="padded">
				<tr>
			<th>17/08/2018</th>
			<th>18/08/2018</th>
			<th>19/08/2018</th>
			<th>20/08/2018</th>
			<th>21/08/2018</th>
			<th>22/08/2018</th>
			<th>23/08/2018</th>
		</tr>
		<tr>
			<td>88</td>
			<td>37</td>
			<td>42</td>
			<td>107</td>
			<td>104</td>
			<td>89</td>
			<td>8</td>
		</tr>
	</table>
		</td>
	</tr>
	<tr>
		<td class="section">
			<h3>
				Fortnight Summary
			</h3>

		<p>
			There is a big focus on computer vision (CV) in research from the papers published in the last two weeks, as reflected on the popularity of the CV datasets used. The interests in CV can be subdivided into handwriting recognition, autonomous driving, face detection, general object classification, and the handling of low-pixel or blurred images.<br /><br />
In other areas of machine learning, there are good developments in both speech recognition (<a href="https://arxiv.org/abs/1808.06719v1">Fast Spectrogram Inversion using Multi-head Convolutional Neural Networks</a>) and natural language processing (NLP) (<a href="https://arxiv.org/abs/1808.06068">SeVeN: Augmenting Word Embeddings with Unsupervised Relation Vectors</a>).<br /><br />
There are also new insights in more general machine learning techniques and understanding, such as better model selection technique (<a href="http://arxiv.org/abs/1808.05296v1"> Model Selection via the VC-Dimension</a>), new understanding of black box machine learning (<a href="http://arxiv.org/abs/1808.05054v1">Shedding Light on Black Box Machine Learning Algorithms: Development of an Axiomatic Framework to Assess the Quality of Methods that Explain Individual Predictions</a>), using small samples (<a href="http://arxiv.org/abs/1808.04572v3">Small Sample Learning in Big Data Era</a>) and new method of outlier detection (<a href="http://arxiv.org/abs/1712.04129v2">Outlier Detection by Consistent Data Selection Method</a>).
		</p>

		</td>
	</tr>
	<tr>
		<td class="section">
			<h3>
				Popular Datasets
			</h3>
			<p>
				Computer vision is still the main focus area of research. The recent papers heavily used ImageNet and MNIST as the top datasets, while LFW was used by seven papers.
			</p>
			<table class="padded"
			    <tr>
			        <th>Name</th>
			        <th>Type</th>
			        <th>Number of Papers</th>
			    </tr>
			    <tr>
						<td><a href="http://yann.lecun.com/exdb/mnist/">MNIST</a></td>
						<td>Handwritten digits</td>
			        <td>35</td>
			    </tr>
			    <tr>
						<td><a href="http://www.image-net.org">ImageNet</a></td>
						<td>Images</td>
			        <td>27</td>
			    </tr>
			    <tr>
						<td><a href="https://www.cityscapes-dataset.com">Cityscapes</a></td>
						<td>Urban street scene</td>
			        <td>15</td>
			    </tr>
			    <tr>
			        <td><a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a></td>
			        <td>Tiny images</td>
			        <td>13</td>
			    </tr>
			    <tr>
						<td><a href="http://cocodataset.org/#home">COCO</a></td>
						<td>Common objects in content</td>
			        <td>11</td>
			    </tr>
			    <tr>
						<td><a href="http://www.cvlibs.net/datasets/kitti/">KITTI</a></td>
						<td>Autonomous driving</td>
			        <td>8</td>
			    </tr>
			    <tr>
						<td><a href="https://rgbd-dataset.cs.washington.edu">RGB-D</a></td>
						<td>Household object</td>
			        <td>7</td>
			    </tr>
			    <tr>
			        <td><a href="http://host.robots.ox.ac.uk/pascal/VOC/">VOC</a></td>
			        <td>Object class recognition</td>
			        <td>7</td>
			    </tr>
			    <tr>
			        <td><a href="http://vis-www.cs.umass.edu/lfw/">LFW</a></td>
			        <td>Face detection</td>
			        <td>7</td>
			    </tr>
			</table>
		</td>
	</tr>

	<tr>
		<td class="section">
			<h3>
				Frequent Words
			</h3>

			<p>
				"Model", "learning" and "data" are the most frequent words. Below is a word cloud of all keywords from the last two weeks papers:
			</p>

			<img class="image_fix" src="https://etymoio.github.io/newsletter/2018-08-24/image/header.png" alt="word cloud of the popularity of keywords" title="word cloud of the popularity of keywords" width="100%"  />
			<p style="margin-bottom:10px">
				The top two papers associated with each of the key words are:
			</p>
			<ul> <b>Model</b>:
				<li>
					<a href="http://arxiv.org/abs/1808.05296v1"> Model Selection via the VC-Dimension</a>
				</li>
				<li>
					<a href="http://arxiv.org/abs/1808.05054v1">Shedding Light on Black Box Machine Learning Algorithms: Development of an Axiomatic Framework to Assess the Quality of Methods that Explain Individual Predictions</a>
				</li>
				<br /> <b>Learning</b>:
				<li>
					<a href="http://arxiv.org/abs/1808.04572v3">Small Sample Learning in Big Data Era</a>
				</li>
				<li>
					<a href="http://arxiv.org/abs/1808.03620v1">Ensemble Kalman Inversion: A Derivative-Free Technique For Machine Learning Tasks</a>
				</li>
				<br /> <b>Data</b>:
				<li>
					<a href="http://arxiv.org/abs/1808.04572v3">Small Sample Learning in Big Data Era</a>
				</li>
				<li>
					<a href="http://arxiv.org/abs/1712.04129v2">Outlier Detection by Consistent Data Selection Method</a>
				</li>
			</ul>
		</td>
	</tr>


	<tr>
		<td>
			<h3>
				Etymo Trending
			</h3>
			<p>
				Presented below is a list of the most trending papers added in the last two weeks. The ranking is constructed from a combination of Etymo stars and tweets. Please star your favourites on Etymo Scholar to influence the results.
			</p>
			<ul>
				<li>
					<a href="https://arxiv.org/abs/1808.06670v1">Evaluating and Understanding the Robustness of Adversarial Logit Pairing:</a> <br /> This 17 page paper hypothesises that representation learning algorithms should be evaluted in terms of information content rather than on a pixel level. The authors define a new method called Deep INFOMAX (DIM) and compare it with Variational autoencoders (VAE), Adversarial autoencoders (AAE), BiGAN and Noise at target (NAT). This paper uses the CIFAR10, CIFAR100, Tiny ImageNet and STL-10 datasets for the comparison between different methods.
				</li>
				<br />
				<li>
					<a href="https://arxiv.org/abs/1808.06719v1">Fast Spectrogram Inversion using Multi-head Convolutional Neural Networks:</a> <br /> This concise 6 page paper proposes a multi-head convolutional neural network (MCNN) architecture for waveform synthesis. The model is compared with the Griffin-Lim (GL) algorithm and the single-pass spectrogram inversion (SPSI) algorithm on the LibriSpeech dataset.
				</li>
				<br />
				<li>
					<a href="https://arxiv.org/abs/1808.06068">SeVeN: Augmenting Word Embeddings with Unsupervised Relation Vectors:</a> <br /> This 14 page paper presents SeVeN (Semantic Vector Networks), an algorithm that encodes relationships between words in the form of a graph. They compare their embeddings in several ways with the word2vec Google News embeddings.
				</li>
			</ul>
		</td>
	</tr>
	</table>

	<tr>
	<td class="section">
		<h4>
				Hope you have enjoyed our very first newsletter! If you have any comments or suggestions, please email ernest@etymo.io or steven@etymo.io.
				If you're having trouble with this email you can read this newsletter online <a href="https://etymoio.github.io/newsletter/2018-08-24">here</a>.
		</h4>
	</td>
	</tr>

</body>
</html>
