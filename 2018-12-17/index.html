<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
	<title>Etymo AI newsletter #9</title>
	<style type="text/css">
		#outlook a {padding:0;}
		body{width:100% !important; -webkit-text-size-adjust:100%; -ms-text-size-adjust:100%; margin:0; padding:0; font-family: "Open Sans", sans-serif;}
		.ExternalClass {width:100%;}
		.ExternalClass, .ExternalClass p, .ExternalClass span, .ExternalClass font, .ExternalClass td, .ExternalClass div {line-height: 100%;}
		#backgroundTable {margin:0; padding:0; width:100% !important; line-height: 100% !important;}
		img {outline:none; text-decoration:none; -ms-interpolation-mode: bicubic;}
		a img {border:none;}
		.image_fix {display:block;}
		p {margin: 1em 0;}
		h1, h2, h4, h5, h6 {color: black !important; font-weight:300; text-align:center;}
		h3 {font-weight:300; text-align:center;}
		h1 a, h2 a, h3 a, h4 a, h5 a, h6 a {color: blue !important;}
		h1 a:active, h2 a:active,  h3 a:active, h4 a:active, h5 a:active, h6 a:active {
			color: red !important;
		}
		h2 {font-size:4rem;}
		h3 {font-size:1.75rem; color:blue;}
		h4 {font-size:1.3rem;}

		h1 a:visited, h2 a:visited,  h3 a:visited, h4 a:visited, h5 a:visited, h6 a:visited {
			color: purple !important;
		}
		table td {border-collapse: collapse;}
		table { border-collapse:collapse; mso-table-lspace:0pt; mso-table-rspace:0pt; }
		a {color: blue;}
		@media only screen and (max-device-width: 480px) {
			a[href^="tel"], a[href^="sms"] {
						text-decoration: none;
						color: black; /* or whatever your want */
						pointer-events: none;
						cursor: default;
					}

			.mobile_link a[href^="tel"], .mobile_link a[href^="sms"] {
						text-decoration: default;
						color: blue !important; /* or whatever your want */
						pointer-events: auto;
						cursor: default;
					}
		}

		@media only screen and (min-device-width: 768px) and (max-device-width: 1024px) {
			a[href^="tel"], a[href^="sms"] {
						text-decoration: none;
						color: blue;
						pointer-events: none;
						cursor: default;
					}

			.mobile_link a[href^="tel"], .mobile_link a[href^="sms"] {
						text-decoration: default;
						color: blue !important;
						pointer-events: auto;
						cursor: default;
					}
		}

		.section{
			padding:10px;
		}
		#backgroundTable{
			width:100%;
			max-width:800px;
			margin:0 auto;
		}
		th{
			text-align:left;
		}
		.padded td, th{
			padding:5px 10px;
		}

		li{
			margin:10px;
		}

		@media only screen and (-webkit-min-device-pixel-ratio: 2) {
			/* Put your iPhone 4g styles in here */
		}
		@media only screen and (-webkit-device-pixel-ratio:.75){
			/* Put CSS for low density (ldpi) Android layouts in here */
		}
		@media only screen and (-webkit-device-pixel-ratio:1){
			/* Put CSS for medium density (mdpi) Android layouts in here */
		}
		@media only screen and (-webkit-device-pixel-ratio:1.5){
			/* Put CSS for high density (hdpi) Android layouts in here */
		}
	</style>



</head>
<body>
	<table cellpadding="0" cellspacing="0" border="0" id="backgroundTable" style="background-color:#ffffff;">
	<tr>
		<td class="section" style="text-align:center;padding:10px;">
			<h1>
				<img class="image_fix" src="https://raw.githubusercontent.com/EtymoIO/newsletter/master/image/header.png" alt="newsletter.etymo" title="newsletter.etymo" style="width:100%	;max-width:600px; margin:0px auto;" />
			</h1>
		</td>
	</tr>
	<tr>
		<td class="section" style="text-align:center;">
			<h2 style="font-weight:300; font-size:2rem;">30th November - 14th December 2018</h2>
			<h3 style="color:blue;">
				1881 new papers
			</h3>
		</td>
	</tr>
	<tr>
		<td class="section">
			<p>
				In this newsletter from Etymo, you can find out the latest development in machine learning research, including the most popular datasets used, the most frequently appearing keywords, the important research papers associated with the keywords, and the most trending papers in the past two weeks.<br /><br />
If you and your friends like this newsletter, you can subscribe to our fortnightly newsletters <a href="https://docs.google.com/forms/d/e/1FAIpQLScPzDcOp6gnVWtiXtLOG_uFff0Fg7uEuXqg0cu5LiCNkq637Q/viewform">here</a>.
			</p>
		</td>
	</tr>
	<tr>
		<td class="section">
			<h3>
				Fortnight Summary
			</h3>
		<p>
			Again computer vision (CV) is still strong, as reflected on the popularity of the CV datasets and the most trending papers. Very little change with the most popular datasets, mainly just a reshuffle of the ordering.<br></br>

			Generative Adversarial Networks (GANs) have been popular over the last two weeks with (<a href="https://arxiv.org/pdf/1811.10597v1.pdf">GAN Dissection: Visualizing and Understanding Generative Adversarial Networks</a>) developing a new framework to help visualise and understand GANs on a unit level, and (<a href="https://arxiv.org/pdf/1811.12402v1.pdf">On the Implicit Assumptions of GANs</a>) which explain the problems with GANs that apparently contradict theoretical guarantees and provide an alternative approach which sidestep these problems. For anyone unfamiliar with GANs, we recommend <a href="https://arxiv.org/pdf/1701.00160v4.pdf">NIPS 2016 Tutorial: Generative Adversarial Networks</a> by Ian Goodfellow. <br></br>

			We present the emerging interests in research under the "Trending Phrases" section. The papers in this section shows some cutting edge results, <a href="http://arxiv.org/abs/1810.07096v2">Incremental learning abstract discrete planning domains and mappings to continuous perceptions</a> provides a new framework for planning (model based) reinforcement learning. They allow the agent to dynamically learn new states, map between states and real world, and update these mapping along the life of the agent. <a href="http://arxiv.org/abs/1712.01949v2">Recognizing Plans by Learning Embeddings from Observed Action Distributions</a> also explores planning domain, where they apply Word2Vec on actions to construct plans. They develop a UDUP (Uncertain DUP|) algorithm, where DUP was originally developed in  <a href="https://arxiv.org/pdf/1511.05662.pdf">Discovering Underlying Plans Based on Distributed Representations of Actions</a>.
			<a href="http://arxiv.org/abs/1811.11168v2">Deformable ConvNets v2: More Deformable, Better Results </a> explores spatial support where they present a reformulation of Deformable ConvNets that improves its ability to focus on pertinent image regions. Finally <a href="http://arxiv.org/abs/1811.08115v2">Sequence-based Person Attribute Recognition with Joint CTC-Attention Model</a> propose a joint CTC-Attention model, which maps attribute labels into sequences to learn the semantic relationship among attributes. Attribute recognition is widely used in many computer vision tasks.<br></br>

			The trending of the last two weeks are from Google and Deepmind, a shot summary of each trending paper is given in the section below.<br></br>

			Other noticable mentions include <a href="https://arxiv.org/pdf/1811.10495v1.pdf">ExpandNets: Exploiting Linear Redundancy to Train Small Networks</a>, which introduces another alternative approach to training a small network. They propose to expand each linear layer of a small network into multiple linear layers, without adding any nonlinearity. <a href="https://arxiv.org/pdf/1811.10154v1.pdf">Please Stop Explaining Black Box Models for High Stakes Decisions</a> want authors to stop explaining black box models, and start creating models that are interpretable in the first place. And finally <a href="https://arxiv.org/pdf/1811.10959v1.pdf">Dataset Distillation</a> which tries to distill a large dataset into a smaller one. This idea is to form a smaller dataset using the the larger dataset and then train on the smaller dataset instead. They compare their method on the ImageNet and CIFAR-10 datasets.
		</p>

		</td>
	</tr>
	<tr>
		<td class="section">
			<h3>
				Popular Datasets
			</h3>
			<p>
				Computer vision is still the main focus area of research.
			</p>
			<table class="padded">
			<tr>
			        <th>Name</th>
			        <th>Type</th>
			        <th>Number of Papers</th>
			</tr>
			<tr>
				<td><a href="http://yann.lecun.com/exdb/mnist/">MNIST</a></td>
				<td>Handwritten Digits</td>
			        <td>98</td>
			</tr>
			<tr>
				<td><a href="http://www.image-net.org">ImageNet</a></td>
				<td>Image Dataset</td>
						<td>63</td>
			</tr>
			<tr>
				<td><a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a></td>
				<td>Tiny Image Dataset in 10 Classes</td>
						<td>52</td>
			</tr>
			<tr>
				<td><a href="http://cocodataset.org/#home">COCO</a></td>
				<td>Common Objects in Context</td>
						<td>30</td>
			</tr>
			<tr>
				<td><a href="http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html">CelebA</a></td>
				<td>Large-scale CelebFaces Attributes</td>
						<td>26</td>
			</tr>
			<tr>
				<td><a href="http://www.cvlibs.net/datasets/kitti/">KITTI</a></td>
				<td>Autonomous Driving</td>
						<td>21</td>
			</tr>
			<tr>
				<td><a href="https://www.cityscapes-dataset.com/">Cityscapes</a></td>
				<td>Images from 50 different cities</td>
					<td>18</td>
			</tr>
			</table>
		</td>
	</tr>

	<tr>
		<td class="section">
			<h3>
				Trending Phrases
			</h3>
			<p>
				In this section, we present a list of words/ phrases that appeared significantly more in this newsletter than the previous newsletters.
			</p>
			<ul> <b>Rule learning</b>:
				<li>
					<a href="https://arxiv.org/abs/1812.00050">Learning Interpretable Rules for Multi-label Classification</a>
				</li>
				<li>
					<a href="https://arxiv.org/abs/1812.02576">That's Mine! Learning Ownership Relations and Norms for Robots</a>
				</li>
				<br /> <b>Trust model</b>:
				<li>
					<a href="https://arxiv.org/abs/1806.03916">A Survey on Trust Modeling from a Bayesian Perspective</a>
				</li>
				<br /> <b>Fake review</b>:
				<li>
					<a href="https://arxiv.org/abs/1812.01661">Graph-based Security and Privacy Analytics via Collective Classification with Joint Weight Learning and Propagation</a>
				</li>
			</ul>
		</td>
	</tr>


	<tr>
		<td>
			<h3>
				Etymo Trending
			</h3>
			<p>
				Presented below is a list of the most trending papers added in the last two weeks.
			</p>
			<ul>
				<li>
					<a href="https://arxiv.org/abs/1811.10597">GAN Dissection: Visualizing and Understanding Generative Adversarial Networks</a>:
					<br />
					The 30 page paper from Deepmind highlights a research direction to solve the agent alignment problem centered around reward modeling. The idea behind reward modelling is to construct a reward function based on user interaction, which can then be used during reinforcement learning. The paper provides a brief literature review and then explains many open problems in the subject.
				</li>
				<br />
				<li>
					<a href="https://arxiv.org/abs/1811.12560">An Introduction to Deep Reinforcement Learning</a>:
					<br />
					This short paper from Google discusses the definition of `unfairness' in machine learning over the last 50 years. Each decade is given a short section and a detailed overview is provided at the end.
				</li>
				<br />
				<li>
					<a href="https://arxiv.org/abs/1812.03973">Bayesian Layers: A Module for Neural Network Uncertainty</a>:
					<br />
					Again Deepmind and Google Brain explore variants of target-propagation (TP) and feedback alignment (FA) algorithms for deep neural nets. Results are presented on results on the MNIST, CIFAR-10, and ImageNet datasets. Then conclude that both approached perform significantly worse than backpropogation.
				</li>
			</ul>
		</td>
	</tr>

	<tr>
		<td class="section">
			<h3>
				Frequent Words
			</h3>

			<p>
				"Learning", "Model", "Data" and "Training" are the most frequent words. The top two papers associated with each of the key words are:
			</p>
			<ul> <b>Model</b>:
				<li>
					<a href="https://arxiv.org/abs/1811.12808">Model Evaluation, Model Selection, and Algorithm Selection in Machine Learning</a>
				</li>
				<li>
					<a href="https://arxiv.org/abs/1810.04261">A Tale of Three Probabilistic Families: Discriminative, Descriptive and Generative Models</a>
				</li>
				<br /> <b>Learning</b>:
				<li>
					<a href="https://arxiv.org/abs/1811.12560">An Introduction to Deep Reinforcement Learning</a>
				</li>
				<li>
					<a href="https://arxiv.org/abs/1809.08267">Neural Approaches to Conversational AI</a>
				</li>
				<br /> <b>Data</b>:
				<li>
					<a href="https://arxiv.org/abs/1812.02855">Progressive Sampling-Based Bayesian Optimization for Efficient and Automatic Machine Learning Model Selection</a>
				</li>
				<li>
					<a href="https://arxiv.org/abs/1812.01790">Hybrid Microaggregation for Privacy-Preserving Data Mining</a>
				</li>
				<br /> <b>Training</b>:
				<li>
					<a href="https://arxiv.org/abs/1811.02625">MixTrain: Scalable Training of Verifiably Robust Neural Networks</a>
				</li>
				<li>
					<a href="https://arxiv.org/abs/1812.02858">Wireless Network Intelligence at the Edge</a>
				</li>
			</ul>
		</td>
	</tr>

	<tr>
	<td class="section">
		<h4 style="line-height:1.25">
				Hope you have enjoyed this newsletter! If you have any comments or suggestions, please email ernest@etymo.io or steven@etymo.io.
		</h4>
	</td>
	</tr>
	</table>

</body>
</html>
