<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
	<title>Etymo AI newsletter #4</title>
	<style type="text/css">
		#outlook a {padding:0;}
		body{width:100% !important; -webkit-text-size-adjust:100%; -ms-text-size-adjust:100%; margin:0; padding:0; font-family: "Open Sans", sans-serif;}
		.ExternalClass {width:100%;}
		.ExternalClass, .ExternalClass p, .ExternalClass span, .ExternalClass font, .ExternalClass td, .ExternalClass div {line-height: 100%;}
		#backgroundTable {margin:0; padding:0; width:100% !important; line-height: 100% !important;}
		img {outline:none; text-decoration:none; -ms-interpolation-mode: bicubic;}
		a img {border:none;}
		.image_fix {display:block;}
		p {margin: 1em 0;}
		h1, h2, h4, h5, h6 {color: black !important; font-weight:300; text-align:center;}
		h3 {font-weight:300; text-align:center;}
		h1 a, h2 a, h3 a, h4 a, h5 a, h6 a {color: blue !important;}
		h1 a:active, h2 a:active,  h3 a:active, h4 a:active, h5 a:active, h6 a:active {
			color: red !important;
		}
		h2 {font-size:4rem;}
		h3 {font-size:1.75rem; color:blue;}
		h4 {font-size:1.5rem; color:blue;}

		h1 a:visited, h2 a:visited,  h3 a:visited, h4 a:visited, h5 a:visited, h6 a:visited {
			color: purple !important;
		}
		table td {border-collapse: collapse;}
		table { border-collapse:collapse; mso-table-lspace:0pt; mso-table-rspace:0pt; }
		a {color: blue;}
		@media only screen and (max-device-width: 480px) {
			a[href^="tel"], a[href^="sms"] {
						text-decoration: none;
						color: black; /* or whatever your want */
						pointer-events: none;
						cursor: default;
					}

			.mobile_link a[href^="tel"], .mobile_link a[href^="sms"] {
						text-decoration: default;
						color: blue !important; /* or whatever your want */
						pointer-events: auto;
						cursor: default;
					}
		}

		@media only screen and (min-device-width: 768px) and (max-device-width: 1024px) {
			a[href^="tel"], a[href^="sms"] {
						text-decoration: none;
						color: blue;
						pointer-events: none;
						cursor: default;
					}

			.mobile_link a[href^="tel"], .mobile_link a[href^="sms"] {
						text-decoration: default;
						color: blue !important;
						pointer-events: auto;
						cursor: default;
					}
		}

		.section{
			padding:10px;
		}
		#backgroundTable{
			width:100%;
			max-width:800px;
			margin:0 auto;
		}
		th{
			text-align:left;
		}
		.padded td, th{
			padding:5px 10px;
		}

		li{
			margin:10px;
		}

		@media only screen and (-webkit-min-device-pixel-ratio: 2) {
			/* Put your iPhone 4g styles in here */
		}
		@media only screen and (-webkit-device-pixel-ratio:.75){
			/* Put CSS for low density (ldpi) Android layouts in here */
		}
		@media only screen and (-webkit-device-pixel-ratio:1){
			/* Put CSS for medium density (mdpi) Android layouts in here */
		}
		@media only screen and (-webkit-device-pixel-ratio:1.5){
			/* Put CSS for high density (hdpi) Android layouts in here */
		}
	</style>



</head>
<body>
	<table cellpadding="0" cellspacing="0" border="0" id="backgroundTable" style="background-color:#ffffff;">
	<tr>
		<td class="section" style="text-align:center;padding:10px;">
			<h1>
				<img class="image_fix" src="https://s3.eu-west-2.amazonaws.com/newsletter.etymo.io/template/header.png" alt="newsletter.etymo" title="newsletter.etymo" style="width:100%	;max-width:600px; margin:0px auto;" />
			</h1>
		</td>
	</tr>
	<tr>
		<td class="section" style="text-align:center;">
			<h2 style="font-weight:300; font-size:2rem;">21st September - 4th October 2018</h2>
		</td>
	</tr>
	<tr>
		<td class="section">
			<p>
				In this newsletter from Etymo, you can find out the latest development in machine learning research, including the most popular datasets used, the most frequently appearing keywords and the important research papers associated with the keywords, and the most trending papers in the past two weeks.<br /><br />
If you and your friends like this newsletter, you can subscribe to our fortnightly newsletters <a href="https://docs.google.com/forms/d/e/1FAIpQLScPzDcOp6gnVWtiXtLOG_uFff0Fg7uEuXqg0cu5LiCNkq637Q/viewform">here</a>.
			</p>
			<h3 style="color:blue;">
				1366 new papers
			</h3>
			<p>
				Etymo added 1366 new papers published in the past two weeks. These newly published papers on average have 3.8 authors for each paper. <br /><br />The bar diagram below indicates the number of papers published each day from some major sources, including arXiv, DeepMind, Facebook and etc. This diagram also indicates the pattern of publishing machine learning research papers.
			</p>
		<img class="image_fix" src="https://s3.eu-west-2.amazonaws.com/newsletter.etymo.io/2018-09-07_2018-09-24/long_term.png"  align="middle" alt="bar chart of papers published daily" title="bar chart of papers published daily" width="75%"  />
		</td>
	</tr>
	<tr>
		<td class="section">
			<h3>
				Fortnight Summary
			</h3>
		<p>
			There was still a strong focus on computer vision (CV) in research from the papers published in the last two weeks, as reflected on the popularity of the CV datasets used. The ranking of the datasets appearing in research papers stayed almost the same compared to the last newsletter. The only non-image based dataset is Twitter.<br></br>

In other areas of machine learning, there were some interesting development in knowledge representation (in robotics and medicine), such as <a href="https://arxiv.org/abs/1508.03891v4">REBA: A Refinement-Based Architecture for Knowledge Representation and Reasoning in Robotics</a>, and <a href="https://arxiv.org/abs/1810.01560v1">Rough set based lattice structure for knowledge representation in medical expert systems: low back pain management case study</a>. <a href="https://arxiv.org/abs/1612.01158v3">Properties and Bayesian fitting of restricted Boltzmann machines</a> explains how the parameter specification of a restricted Boltzmann machine (RBM) is related to model properties such as degeneracy, instability and uninterpretability. This gives us a better fundamental understanding of deep learning. <a href="https://arxiv.org/abs/1808.08414v2">
Unsupervised Hypergraph Feature Selection via a Novel Point-Weighting Framework and Low-Rank Representation</a> presents a new feature selection method, which has low computation cost (much higher efficiency) but similar performance compared with state-of-the-art feature selection methods.<br></br>

In the past two weeks, there was a great tool developed in R to audit machine learning models of any classes (<a href="https://arxiv.org/abs/1809.07763v3">auditor: an R Package for Model-Agnostic Visual Validation and Diagnostic</a>). In addition, there were some good summaries and reviews to help better understand existing machine learning approaches and the current machine learning status. These summaries/reviews include <a href="https://arxiv.org/abs/1809.09337v2">A Survey of Learning Causality with Data: Problems and Methods</a>, <a href="https://arxiv.org/abs/1809.08267v1">Neural Approaches to Conversational AI</a>, and <a href="https://arxiv.org/abs/1809.10024v1">Computational and informatics advances for reproducible data analysis in neuroimaging</a>. There was also a very popular textbook-like document, <a href="https://arxiv.org/abs/1809.10756v1">An Introduction to Probabilistic Programming</a>, which is also included in the trending section of this newsletter.<br></br>

The trending of the last two weeks was still skewed towards computer vision: a new state-of-the-art class-conditional image synthesis method using large scale GAN (<a href="https://arxiv.org/abs/1809.11096v1">Large Scale GAN Training for High Fidelity Natural Image Synthesis</a>), and a new general approach using unsupervised learning, called Deep Graph Infomax (DGI), for learning node representations with graph-structured data (<a href="https://arxiv.org/abs/1809.10341v1">Deep Graph Infomax</a>).
		</p>

		</td>
	</tr>
	<tr>
		<td class="section">
			<h3>
				Popular Datasets
			</h3>
			<p>
				Computer vision is still the main focus area of research. The ranking of the datasets used has not changed much compared to the last newsletter. SVHN (Street View House Numbers Dataset) is near the top for the first time. It is also the first time we have seen CIFAR-100 near the top, which is the same dataset as CIFAR-10 but images are classified into 100 classes instead of 10.
			</p>
			<table class="padded"
			    <tr>
			        <th>Name</th>
			        <th>Type</th>
			        <th>Number of Papers</th>
			    </tr>
			    <tr>
						<td><a href="http://yann.lecun.com/exdb/mnist/">MNIST</a></td>
						<td>Handwritten Digits</td>
			        <td>54</td>
			    </tr>
			    <tr>
						<td><a href="http://www.image-net.org">ImageNet</a></td>
						<td>Image Dataset</td>
			        <td>42</td>
			    </tr>
					<tr>
							<td><a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a></td>
							<td>Tiny Image Dataset in 10 Classes</td>
							<td>28</td>
					</tr>
					<tr>
						<td><a href="http://cocodataset.org/#home">COCO</a></td>
						<td>Common Objects in Context</td>
							<td>16</td>
					</tr>
					<tr>
						<td><a href="https://www.cityscapes-dataset.com">Cityscapes</a></td>
						<td>Urban Street Scenes</td>
							<td>12</td>
					</tr>
					<tr>
						<td><a href="http://www.cvlibs.net/datasets/kitti/">KITTI</a></td>
						<td>Autonomous Driving</td>
							<td>12</td>
					</tr>
					<tr>
						<td>Twitter</td>
						<td>Tweets</td>
							<td>12</td>
					</tr>
					<tr>
							<td><a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-100</a></td>
							<td>Tiny Image Dataset in 100 Classes</td>
							<td>9</td>
					</tr>
					<tr>
						<td><a href="http://ufldl.stanford.edu/housenumbers/">SVHN</a></td>
						<td>The Street View House Numbers Dataset</td>
							<td>8</td>
					</tr>
			</table>
		</td>
	</tr>

	<tr>
		<td class="section">
			<h3>
				Frequent Words
			</h3>

			<p>
				"Learning", "Model", "Data" and "Set" are the most frequent words, yet again. Below is a word cloud of all keywords from the last two weeks papers:
			</p>

			<img class="image_fix" src="https://s3.eu-west-2.amazonaws.com/newsletter.etymo.io/2018-09-07_2018-09-24/KeyphraseWordCloud.png" alt="word cloud of the popularity of keywords" title="word cloud of the popularity of keywords" width="100%"  />
			<p style="margin-bottom:10px">
				The top two papers associated with each of the key words are:
			</p>
			<ul> <b>Model</b>:
				<li>
					<a href="https://arxiv.org/abs/1809.07763v3">an R Package for Model-Agnostic Visual Validation and Diagnostic</a>
				</li>
				<li>
					<a href="https://arxiv.org/abs/1612.01158v3">Properties and Bayesian fitting of restricted Boltzmann machines</a>
				</li>
				<br /> <b>Learning</b>:
				<li>
					<a href="https://arxiv.org/abs/1809.09337v2">A Survey of Learning Causality with Data: Problems and Methods</a>
				</li>
				<li>
					<a href="https://arxiv.org/abs/1809.08267v1">Neural Approaches to Conversational AI</a>
				</li>
				<br /> <b>Data</b>:
				<li>
					<a href="https://arxiv.org/abs/1809.10024v1">Computational and informatics advances for reproducible data analysis in neuroimaging</a>
				</li>
				<li>
					<a href="https://arxiv.org/abs/1808.08414v2">Unsupervised Hypergraph Feature Selection via a Novel Point-Weighting Framework and Low-Rank Representation</a>
				</li>

				<br /> <b>Set</b>:
				<li>
					<a href="https://arxiv.org/abs/1810.01560v1">Rough set based lattice structure for knowledge representation in medical expert systems: low back pain management case study</a>
				</li>
				<li>
					<a href="https://arxiv.org/abs/1508.03891v4">REBA: A Refinement-Based Architecture for Knowledge Representation and Reasoning in Robotics</a>
				</li>
			</ul>
		</td>
	</tr>


	<tr>
		<td>
			<h3>
				Etymo Trending
			</h3>
			<p>
				Presented below is a list of the most trending papers added in the last two weeks.
			</p>
			<ul>
				<li>
					<a href="https://arxiv.org/abs/1809.11096v1">Large Scale GAN Training for High Fidelity Natural Image Synthesis</a>:
					<br />
					This 29-page paper uses a large scale GAN (Generative Adversarial Networks) model, with orthogonal regularization to the generator, to achieve the new state-of-the-art class-conditional image synthesis. In this paper, the authors explored a fine control of the trade-off between sample fidelity and variety by truncating the latent space.
				</li>
				<br />
				<li>
					<a href="https://arxiv.org/abs/1809.10756v1">An Introduction to Probabilistic Programming</a>:
					<br />
					A textbook style document co-authored by field experts from the US, the UK, Canada and Korea. This document is desinged to introduce probabilistic programming to first-year graduate-level students, or anyone who has an undergraduate-level understading of idealy both probabilistic machine learning and programming languages. This document contains 218 pages.
				</li>
				<br />
				<li>
					<a href="https://arxiv.org/abs/1809.10341v1">Deep Graph Infomax</a>:
					<br />
					This 15-page paper presents Deep Graph Infomax (DGI), a general approach for learning node representations with graph-structured data using unsupervised learning. DGI does not rely on random walk, and is readily applicable to both transductive and inductive learning setups. Its performance is competitive on a variety of node classification benchmarks, and sometimes exceeding the performance of supervised learning.
				</li>
			</ul>
		</td>
	</tr>
	</table>

	<tr>
	<td class="section">
		<h4>
				Hope you have enjoyed this newsletter! If you have any comments or suggestions, please email ernest@etymo.io or steven@etymo.io.
		</h4>
	</td>
	</tr>

</body>
</html>
