<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
	<title>Etymo AI newsletter #5</title>
	<style type="text/css">
		#outlook a {padding:0;}
		body{width:100% !important; -webkit-text-size-adjust:100%; -ms-text-size-adjust:100%; margin:0; padding:0; font-family: "Open Sans", sans-serif;}
		.ExternalClass {width:100%;}
		.ExternalClass, .ExternalClass p, .ExternalClass span, .ExternalClass font, .ExternalClass td, .ExternalClass div {line-height: 100%;}
		#backgroundTable {margin:0; padding:0; width:100% !important; line-height: 100% !important;}
		img {outline:none; text-decoration:none; -ms-interpolation-mode: bicubic;}
		a img {border:none;}
		.image_fix {display:block;}
		p {margin: 1em 0;}
		h1, h2, h4, h5, h6 {color: black !important; font-weight:300; text-align:center;}
		h3 {font-weight:300; text-align:center;}
		h1 a, h2 a, h3 a, h4 a, h5 a, h6 a {color: blue !important;}
		h1 a:active, h2 a:active,  h3 a:active, h4 a:active, h5 a:active, h6 a:active {
			color: red !important;
		}
		h2 {font-size:4rem;}
		h3 {font-size:1.75rem; color:blue;}
		h4 {font-size:1.5rem; color:blue;}

		h1 a:visited, h2 a:visited,  h3 a:visited, h4 a:visited, h5 a:visited, h6 a:visited {
			color: purple !important;
		}
		table td {border-collapse: collapse;}
		table { border-collapse:collapse; mso-table-lspace:0pt; mso-table-rspace:0pt; }
		a {color: blue;}
		@media only screen and (max-device-width: 480px) {
			a[href^="tel"], a[href^="sms"] {
						text-decoration: none;
						color: black; /* or whatever your want */
						pointer-events: none;
						cursor: default;
					}

			.mobile_link a[href^="tel"], .mobile_link a[href^="sms"] {
						text-decoration: default;
						color: blue !important; /* or whatever your want */
						pointer-events: auto;
						cursor: default;
					}
		}

		@media only screen and (min-device-width: 768px) and (max-device-width: 1024px) {
			a[href^="tel"], a[href^="sms"] {
						text-decoration: none;
						color: blue;
						pointer-events: none;
						cursor: default;
					}

			.mobile_link a[href^="tel"], .mobile_link a[href^="sms"] {
						text-decoration: default;
						color: blue !important;
						pointer-events: auto;
						cursor: default;
					}
		}

		.section{
			padding:10px;
		}
		#backgroundTable{
			width:100%;
			max-width:800px;
			margin:0 auto;
		}
		th{
			text-align:left;
		}
		.padded td, th{
			padding:5px 10px;
		}

		li{
			margin:10px;
		}

		@media only screen and (-webkit-min-device-pixel-ratio: 2) {
			/* Put your iPhone 4g styles in here */
		}
		@media only screen and (-webkit-device-pixel-ratio:.75){
			/* Put CSS for low density (ldpi) Android layouts in here */
		}
		@media only screen and (-webkit-device-pixel-ratio:1){
			/* Put CSS for medium density (mdpi) Android layouts in here */
		}
		@media only screen and (-webkit-device-pixel-ratio:1.5){
			/* Put CSS for high density (hdpi) Android layouts in here */
		}
	</style>



</head>
<body>
	<table cellpadding="0" cellspacing="0" border="0" id="backgroundTable" style="background-color:#ffffff;">
	<tr>
		<td class="section" style="text-align:center;padding:10px;">
			<h1>
				<img class="image_fix" src="https://s3.eu-west-2.amazonaws.com/newsletter.etymo.io/template/header.png" alt="newsletter.etymo" title="newsletter.etymo" style="width:100%	;max-width:600px; margin:0px auto;" />
			</h1>
		</td>
	</tr>
	<tr>
		<td class="section" style="text-align:center;">
			<h2 style="font-weight:300; font-size:2rem;">5th October - 18th October 2018</h2>
		</td>
	</tr>
	<tr>
		<td class="section">
			<p>
				In this newsletter from Etymo, you can find out the latest development in machine learning research, including the most popular datasets used, the most frequently appearing keywords and the important research papers associated with the keywords, and the most trending papers in the past two weeks.<br /><br />
If you and your friends like this newsletter, you can subscribe to our fortnightly newsletters <a href="https://docs.google.com/forms/d/e/1FAIpQLScPzDcOp6gnVWtiXtLOG_uFff0Fg7uEuXqg0cu5LiCNkq637Q/viewform">here</a>.
			</p>
			<h3 style="color:blue;">
				1457 new papers
			</h3>
			<p>
				Due to some technical issues, the newsletter was produced one day later than the normal timeline. Please accept our appologies and thank you for the patience. We send out the newsletter on evvery other Monday! Since the last newsletter, Etymo added 1457 new papers published in the past two weeks.
		</td>
	</tr>
	<tr>
		<td class="section">
			<h3>
				Fortnight Summary
			</h3>
		<p>
			In this newsletter, we changed the sequence of sections to reflect users' interests and feedbacks.<br></br>
			There was a strong focus on computer vision (CV) in research from the papers published in the last two weeks, as reflected on the popularity of the CV datasets used. The ranking of the datasets appearing in research papers stayed almost the same compared to the last couple of newsletters. The previoiusly top non-image based dataset of Twitter also dropped this time.<br></br>

In the past two weeks, there was a strong surge in interests in Saliency Models (spotting the focus/attention objects in images), as reflected in the "Trending Phrases" section. The popular papers in Saliency Models include a review of the start-of-the-art technologies (<a href="https://arxiv.org/abs/1810.05680v1">Bottom-up Attention, Models of</a>), and two interesting studies on the gap between the current technologies and human performance (<a href="https://arxiv.org/abs/1810.03716v2">Saliency Prediction in the Deep Learning Era: An Empirical Investigation</a> and <a href="https://arxiv.org/abs/1810.04456v1">
Invariance Analysis of Saliency Models versus Human Gaze During Scene Free Viewing</a>). There was also an emergence of interest in motion vectors for video processing, including <a href="https://arxiv.org/abs/1810.06827v1">Combined Static and Motion Features for Deep-Networks Based Activity Recognition in Videos</a> and <a href="https://arxiv.org/abs/1803.07742v4">Fast Semantic Segmentation on Video Using Block Motion-Based Feature Interpolation</a>.<br></br>

The trending of the last two weeks included a milestone research paper on NLP, using a new technique BERT that exceeds human performance (<a href="https://arxiv.org/abs/1810.04805v1">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a>), and Meta-Learning, consisting of a review (<a href="https://arxiv.org/abs/1810.03548v1">Meta-Learning: A Survey</a>) and a new algorithm (<a href="https://arxiv.org/abs/1810.02334v3">Unsupervised Learning via Meta-Learning</a>).<br></br>

In other areas of machine learning, there were again reviews and summaries of current machine learning status (<a href="https://arxiv.org/abs/1810.07862v1">Applications of Deep Reinforcement Learning in Communications and Networking: A Survey</a>, and <a href="https://arxiv.org/abs/1805.05052v8">Machine Learning: Basic Principles</a>). There were also a new method for clustering (<a href="https://arxiv.org/abs/1501.03347v2">Dirichlet Process Parsimonious Mixtures for clustering</a>), a practical framework for wider application of machine learning (<a href="https://arxiv.org/abs/1810.03993v1">Model Cards for Model Reporting</a>), and a new prediction algorithm (<a href="https://arxiv.org/abs/1810.07776v1">
A Periodicity-based Parallel Time Series Prediction Algorithm in Cloud Computing Environments</a>). Last but not least, there were interesting studies on selecting the optimal subsets from a well-defined set, such as optimal dataset reduction (<a href="https://arxiv.org/abs/1810.08047v1">
Finding Average Regret Ratio Minimizing Set in Database</a>), and problem set optimisation(<a href="https://arxiv.org/abs/1611.04535v4">Learning-Theoretic Foundations of Algorithm Configuration for Combinatorial Partitioning Problems</a>).
		</p>

		</td>
	</tr>
	<tr>
		<td class="section">
			<h3>
				Popular Datasets
			</h3>
			<p>
				Computer vision is still the main focus area of research. The ranking of the datasets used has not changed much compared to the last newsletter. RGB-D, a large dataset of 300 common household objects in 3D, is near the top for the first time.
			</p>
			<table class="padded"
			    <tr>
			        <th>Name</th>
			        <th>Type</th>
			        <th>Number of Papers</th>
			    </tr>
			    <tr>
						<td><a href="http://yann.lecun.com/exdb/mnist/">MNIST</a></td>
						<td>Handwritten Digits</td>
			        <td>62</td>
			    </tr>
			    <tr>
						<td><a href="http://www.image-net.org">ImageNet</a></td>
						<td>Image Dataset</td>
			        <td>31</td>
			    </tr>
					<tr>
							<td><a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a></td>
							<td>Tiny Image Dataset in 10 Classes</td>
							<td>28</td>
					</tr>
					<tr>
						<td><a href="http://cocodataset.org/#home">COCO</a></td>
						<td>Common Objects in Context</td>
							<td>12</td>
					</tr>
					<tr>
						<td><a href="https://www.cityscapes-dataset.com">Cityscapes</a></td>
						<td>Urban Street Scenes</td>
							<td>12</td>
					</tr>
					<tr>
						<td><a href="http://www.cvlibs.net/datasets/kitti/">KITTI</a></td>
						<td>Autonomous Driving</td>
							<td>11</td>
					</tr>
					<tr>
						<td><a href="https://rgbd-dataset.cs.washington.edu/">RGB-D</td>
						<td>3D Image Dataset</td>
							<td>9</td>
					</tr>
					<tr>
							<td><a href="http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html">CelebA</a></td>
							<td>Large-scale CelebFaces Attributes</td>
							<td>9</td>
					</tr>
					<tr>
						<td><a href="http://ufldl.stanford.edu/housenumbers/">SVHN</a></td>
						<td>The Street View House Numbers Dataset</td>
							<td>9</td>
					</tr>
			</table>
		</td>
	</tr>

	<tr>
		<td class="section">
			<h3>
				Trending Phrases
			</h3>
			<p>
				We have started monitoring trending words/ phrases. Below are a list of words/ phrases that appeared significantly more in this newsletter than the previous newsletters.
			</p>
			<ul> <b>Saliency Models</b>:
				<li>
					<a href="https://arxiv.org/abs/1810.05680v1">Bottom-up Attention, Models of</a>
				</li>
				<li>
					<a href="https://arxiv.org/abs/1810.04456v1">Invariance Analysis of Saliency Models versus Human Gaze During Scene Free Viewing</a>
				</li>
				<li>
					<a href="https://arxiv.org/abs/1810.03716v2">Saliency Prediction in the Deep Learning Era: An Empirical Investigation</a>
				</li>
				<br /> <b>Motion Vectors</b>:
				<li>
					<a href="https://arxiv.org/abs/1803.07742v4">Fast Semantic Segmentation on Video Using Block Motion-Based Feature Interpolation</a>
				</li>
				<li>
					<a href="https://arxiv.org/abs/1810.06827v1">Combined Static and Motion Features for Deep-Networks Based Activity Recognition in Videos</a>
				</li>
			</ul>
		</td>
	</tr>


	<tr>
		<td>
			<h3>
				Etymo Trending
			</h3>
			<p>
				Presented below is a list of the most trending papers added in the last two weeks.
			</p>
			<ul>
				<li>
					<a href="https://arxiv.org/abs/1810.04805v1">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a>:
					<br />
					Authors from Google AI produced this milestone paper in NLP, introducing Bidirectional Encoder Representations from Transformers (BERT). BERT achieves new state-of-the-art results on eleven natural language processing tasks, outperforming human performance by 2.0%. It is worth noting that the training of the base dataset of BERT took 4 days with 4 Cloud TPUs, while the training of the large dataset of BERT took 4 days with 16 Cloud TPUs.
				</li>
				<br />
				<li>
					<a href="https://arxiv.org/abs/1810.03548v1">Meta-Learning: A Survey</a>:
					<br />
					This paper provides an overview of the state-of-the-art technologies in the realm of meta-learning in 29 pages.
				</li>
				<br />
				<li>
					<a href="https://arxiv.org/abs/1810.02334v3">Unsupervised Learning via Meta-Learning</a>:
					<br />
					This 21-page paper presents an unsupervised learning method that explicitly optimizes for the ability to learn a variety of tasks from small amounts of data. When integrated with meta-learning, relatively simple mechanisms for task design, such as clustering unsupervised representations, lead to good performance on a variety of downstream tasks.
				</li>
			</ul>
		</td>
	</tr>

	<tr>
		<td class="section">
			<h3>
				Frequent Words
			</h3>

			<p>
				"Learning", "Model", "Data" and "Set" are the most frequent words. The top two papers associated with each of the key words are:
			</p>
			<ul> <b>Model</b>:
				<li>
					<a href="https://arxiv.org/abs/1501.03347v2">Dirichlet Process Parsimonious Mixtures for clustering</a>
				</li>
				<li>
					<a href="https://arxiv.org/abs/1810.03993v1">Model Cards for Model Reporting</a>
				</li>
				<br /> <b>Learning</b>:
				<li>
					<a href="https://arxiv.org/abs/1810.06746v1">Using Deep Reinforcement Learning for the Continuous Control of Robotic Arms</a>
				</li>
				<li>
					<a href="https://arxiv.org/abs/1810.07862v1">Applications of Deep Reinforcement Learning in Communications and Networking: A Survey</a>
				</li>
				<br /> <b>Data</b>:
				<li>
					<a href="https://arxiv.org/abs/1805.05052v8">Machine Learning: Basic Principles</a>
				</li>
				<li>
					<a href="https://arxiv.org/abs/1810.07776v1">A Periodicity-based Parallel Time Series Prediction Algorithm in Cloud Computing Environments</a>
				</li>
				<br /> <b>Set</b>:
				<li>
					<a href="https://arxiv.org/abs/1611.04535v4">Learning-Theoretic Foundations of Algorithm Configuration for Combinatorial Partitioning Problems</a>
				</li>
				<li>
					<a href="https://arxiv.org/abs/1810.08047v1">Finding Average Regret Ratio Minimizing Set in Database</a>
				</li>
			</ul>
		</td>
	</tr>
	</table>

	<tr>
	<td class="section">
		<h4>
				Hope you have enjoyed this newsletter! If you have any comments or suggestions, please email ernest@etymo.io or steven@etymo.io.
		</h4>
	</td>
	</tr>

</body>
</html>
