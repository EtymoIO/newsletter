<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
	<title>Etymo AI newsletter #19</title>
	<style type="text/css">
		#outlook a {padding:0;}
		body{width:100% !important; -webkit-text-size-adjust:100%; -ms-text-size-adjust:100%; margin:0; padding:0; font-family: "Open Sans", sans-serif;}
		.ExternalClass {width:100%;}
		.ExternalClass, .ExternalClass p, .ExternalClass span, .ExternalClass font, .ExternalClass td, .ExternalClass div {line-height: 100%;}
		#backgroundTable {margin:0; padding:0; width:100% !important; line-height: 100% !important;}
		img {outline:none; text-decoration:none; -ms-interpolation-mode: bicubic;}
		a img {border:none;}
		.image_fix {display:block;}
		p {margin: 1em 0;}
		h1, h2, h4, h5, h6 {color: black !important; font-weight:300; text-align:center;}
		h3 {font-weight:300; text-align:center;}
		h1 a, h2 a, h3 a, h4 a, h5 a, h6 a {color: blue !important;}
		h1 a:active, h2 a:active,  h3 a:active, h4 a:active, h5 a:active, h6 a:active {
			color: red !important;
		}
		h2 {font-size:4rem;}
		h3 {font-size:1.75rem; color:blue;}
		h4 {font-size:1.3rem;}

		h1 a:visited, h2 a:visited,  h3 a:visited, h4 a:visited, h5 a:visited, h6 a:visited {
			color: purple !important;
		}
		table td {border-collapse: collapse;}
		table { border-collapse:collapse; mso-table-lspace:0pt; mso-table-rspace:0pt; }
		a {color: blue;}
		@media only screen and (max-device-width: 480px) {
			a[href^="tel"], a[href^="sms"] {
						text-decoration: none;
						color: black; /* or whatever your want */
						pointer-events: none;
						cursor: default;
					}

			.mobile_link a[href^="tel"], .mobile_link a[href^="sms"] {
						text-decoration: default;
						color: blue !important; /* or whatever your want */
						pointer-events: auto;
						cursor: default;
					}
		}

		@media only screen and (min-device-width: 768px) and (max-device-width: 1024px) {
			a[href^="tel"], a[href^="sms"] {
						text-decoration: none;
						color: blue;
						pointer-events: none;
						cursor: default;
					}

			.mobile_link a[href^="tel"], .mobile_link a[href^="sms"] {
						text-decoration: default;
						color: blue !important;
						pointer-events: auto;
						cursor: default;
					}
		}

		.section{
			padding:10px;
		}
		#backgroundTable{
			width:100%;
			max-width:800px;
			margin:0 auto;
		}
		th{
			text-align:left;
		}
		.padded td, th{
			padding:5px 10px;
		}

		li{
			margin:10px;
		}

		@media only screen and (-webkit-min-device-pixel-ratio: 2) {
			/* Put your iPhone 4g styles in here */
		}
		@media only screen and (-webkit-device-pixel-ratio:.75){
			/* Put CSS for low density (ldpi) Android layouts in here */
		}
		@media only screen and (-webkit-device-pixel-ratio:1){
			/* Put CSS for medium density (mdpi) Android layouts in here */
		}
		@media only screen and (-webkit-device-pixel-ratio:1.5){
			/* Put CSS for high density (hdpi) Android layouts in here */
		}
	</style>



</head>
<body>
	<table cellpadding="0" cellspacing="0" border="0" id="backgroundTable" style="background-color:#ffffff;">
	<tr>
		<td class="section" style="text-align:center;padding:10px;">
			<h1>
				<img class="image_fix" src="https://raw.githubusercontent.com/EtymoIO/newsletter/master/image/header.png" alt="newsletter.etymo" title="newsletter.etymo" style="width:100%	;max-width:600px; margin:0px auto;" />
			</h1>
		</td>
	</tr>
	<tr>
		<td class="section" style="text-align:center;">
			<h2 style="font-weight:300; font-size:2rem;">23rd April - 2nd May 2019</h2>
			<!-- <h3 style="color:blue;">
				1438 new papers
			</h3> -->
		</td>
	</tr>
	<tr>
		<td class="section">
			<p>
				Etymo Newsletter provides the latest development in machine learning research,
				including the most popular datasets and the most trending papers in the past two weeks.<br/><br/>
				If you like this newsletter, you can subscribe to our fortnightly newsletters <a href="https://docs.google.com/forms/d/e/1FAIpQLScPzDcOp6gnVWtiXtLOG_uFff0Fg7uEuXqg0cu5LiCNkq637Q/viewform">here</a>.
			</p>
		</td>
	</tr>
	<tr>
		<td class="section">
			<h3>
				Fortnight Summary
			</h3>

			Popular datasets include MNIST, ImageNet, COCO, and KITTI.
			Our trending phrases are Light Field, Truth Discovery, and Pairwise Learning.
			Three trending papers are related to GCNet, Unsupervised Data Augementation,
			and an image extractor using local retention networks.
 			We also present you a collection of recent review papers in AI/Machine Learning.
		</td>
	</tr>
	<tr>
		<td class="section">
			<h3>
				Popular Datasets
			</h3>
			<p>
				Here are most mentioned datasets over the last two weeks.
			</p>
			<table class="padded">
			<tr>
			        <th>Name</th>
			        <th>Type</th>
			        <th>Number of Papers</th>
			</tr>
			<tr>
				<td><a href="http://yann.lecun.com/exdb/mnist/">MNIST</a></td>
				<td>Handwritten Digits</td>
			        <td>58</td>
			</tr>
			<tr>
				<td><a href="http://www.image-net.org">ImageNet</a></td>
				<td>Image Dataset</td>
				<td>35</td>
			</tr>
			<tr>
				<td><a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a></td>
				<td>Tiny Image Dataset in 10 Classes</td>
				<td>30</td>
			</tr>
			<tr>
				<td><a href="http://cocodataset.org/#home">COCO</a></td>
				<td>Common Objects in Context</td>
				<td>21</td>
			</tr>
			<tr>
				<td><a href="http://www.cvlibs.net/datasets/kitti/">KITTI</a></td>
				<td>Autonomous Driving</td>
				<td>14</td>
			</tr>
			<tr>
				<td><a href="https://www.cityscapes-dataset.com/">Cityscapes</a></td>
				<td>Images from 50 different cities</td>
				<td>11</td>
			</tr>
			<tr>
				<td><a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-100</a></td>
				<td>Tiny Image Dataset in 100 Classes</td>
				<td>11</td>
			</tr>
			</table>
		</td>
	</tr>

	<tr>
		<td class="section">
			<h3>
				Trending Phrases
			</h3>
			<p>
				In this section, we present a list of phrases that appeared significantly more in this newsletter than the previous newsletters.
			</p>
			<ul> <b>Light Field</b>:
				<li>
					<a href="https://arxiv.org/abs/1905.00889">Local Light Field Fusion: Practical View Synthesis with Prescriptive Sampling Guidelines</a>
				</li>
				<br /> <b>Truth Discovery</b>:
				<li>
					<a href="https://arxiv.org/abs/1806.02954">Using Social Network Information in Bayesian Truth Discovery</a>
				</li>
				<br /> <b>Pairwise Learning</b>:
				<li>
					<a href="https://arxiv.org/abs/1904.11316">Stability and Optimization Error of Stochastic Gradient Descent for Pairwise Learning</a>
				</li>
				<li>
					<a href="https://arxiv.org/abs/1905.00805">Spectrum-enhanced Pairwise Learning to Rank</a>
				</li>
			</ul>
		</td>
	</tr>


	<tr>
		<td class="section">
			<h3>
				Etymo Trending
			</h3>
			<p>
				Presented below is a list of the most trending papers added in the last two weeks.
			</p>
			<ul>
				<li>
					<a href="https://arxiv.org/abs/1904.11492">GCNet: Non-local Networks Meet Squeeze-Excitation Networks and Beyond</a>:
					<br />
					The authors designed a global context network (GCNet), which unifies both simplified NLNet and SENet
					and enhances it with a lightweight instantiation. GCNet generally outperforms both simplified NLNet
					and SENet on major benchmarks for various recognition tasks. The code and configurations are also available.

				</li>
				<br />
				<li>
					<a href="https://arxiv.org/abs/1904.12848">Unsupervised Data Augmentation</a>:
					<br />
					This paper proposes to apply data augmentation to unlabeled data in a semi-supervised learning setting.
					The method, named Unsupervised Data Augmentation or UDA, encourages the model predictions to be
					consistent between an unlabeled example and an augmented unlabeled example, by using
					state-of-the-art data augmentation methods.
				</li>
				<br />
				<li>
					<a href="https://arxiv.org/abs/1904.11491">Local Relation Networks for Image Recognition</a>:
					<br />
					The authors present a new image feature extractor, called the local relation layer,
					that adaptively determines aggregation weights based on the compositional relationship
					of local pixel pairs. It can composite visual elements into higher-level entities in
					a more efficient manner that benefits semantic inference.
				</li>
			</ul>
		</td>
	</tr>

	<tr>
		<td class="section">
			<h3>
				A Collection of Notable Review Papers
			</h3>
			<ul>
				<li>
					<a href="https://arxiv.org/abs/1904.08067">Text Classification Algorithms: A Survey</a>
				</li>
				<li>
					<a href="https://arxiv.org/abs/1904.10370">A survey on Big Data and Machine Learning for Chemistry</a>
				</li>
				<li>
					<a href="https://arxiv.org/abs/1904.12054">Survey on Automated Machine Learning</a>
				</li>
				<li>
					<a href="https://arxiv.org/abs/1904.12218">Graph Kernels: A Survey</a>
				</li>
			</ul>
		</td>
	</tr>

	<tr>
	<td class="section">
		<h4 style="line-height:1.25">
				Hope you have enjoyed this newsletter! If you have any comments or suggestions, please email ernest@etymo.io or steven@etymo.io.
		</h4>
	</td>
	</tr>
	</table>

</body>
</html>
